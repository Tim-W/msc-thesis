\chapter{\label{chap:evaluation}Evaluation}
We evaluated the viability of our DAO as a Big Tech alternative. An ideal evaluation would be by measuring the impact of a large-scale (millions of users) and long term deployment of MusicDAO in terms of artist income and artist happiness. However, the time and scale required is not feasible in the scope of this thesis. Instead, we deploy MusicDAO on a smaller scale (20 Android devices, 11 users). We measure performance of money transaction flow, music streaming and search latency in supervised and unsupervised experiments. These measurements determine the responsiveness of our infrastructure in small network sizes. By comparing latency and throughput in several network sizes, we can make conclusions of the performance of our infrastructure in larger networks.

In an \textit{unsupervised} experiment, all test subjects are given the MusicDAO application and are asked to stream music and send money to artists, but with no specific rules or guidelines. We have no control over the actions of these test subjects.

In multiple \textit{supervised} experiments, we use 10 Android devices that are under our control. we measure latency and throughput of music data and money transfers, and analyze the impact of network size on these measurements.

% Discuss influence of BEP42 in bittorrent DHT network, our seedbox nodes may be blacklisted or throtled by other DHT nodes because our seedboxes are seeding a large amount of torrents (100) while having only 1 static ipv4 address

\section{Unsupervised experiment: public release}
MusicDAO was released publicly on the Google Play store and 11 test subjects were given the task to download music and send donations to artists. Upon installation and first running MusicDAO, it sends a request in the background to our Bitcoin node, asking for 10 coins in starter money. The responsiveness of our Bitcoin node for transferring starter money is analyzed in \ref{chap:starter-money-flow}.

\subsection{Automated starter money transactions}
\label{chap:starter-money-flow}
We analyze the responsiveness of our bitcoin node by obtaining two datasets, and inspecting their correlation in terms of timing of events.

The two datasets are: 
\begin{enumerate}
    \item App installations per day, as measured by the Google Play console.
    \item Transactions from our Bitcoin node with a value of 10 coins, scraped from our blockchain.
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{evaluation/faucet-app-installs.png}
    \caption{Graph showing the relationship between faucet transactions of 10BTC and app installations. Every app installation should correspond to at least one faucet transaction.}
    \label{fig:faucet-app-installs}
\end{figure}
When there are $x$ app installations on some day, there should be $y \gte x$ transactions outgoing from our Bitcoin faucet. In the graph shown in fig this is not always the case. On 19-01-2021 there was (at least) one transaction missing. This was due to a server outage where the Bitcoin faucet was running. There are also cases in which there are transactions but no installations. This may be due to multiple app installations from one device on the same day (which is measured as one by the Google Play store console) or app installations outside of the Play store. 

\subsection{Donation money flow}
\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{evaluation/artist-income.png}
    \caption{Artist income (cumulative) over time and block creation}
    \label{fig:artist-income}
\end{figure}
% We observe that artist income is 

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{evaluation/transactions.png}
    \caption{Transactions (cumulative) over time and block creation}
    \label{fig:transactions}
\end{figure}

The datasets used to create the plots shown in figs. \ref{fig:artist-income} and \ref{fig:transactions} are received by scraping blockchain block data from our Bitcoin node. Fig. \ref{fig:artist-income} shows the relation between created blocks and money transacted per block (cumulative). We observe that, during the timeline of the release experiment, nearly 500 BTC has been received by artists.

Note that the Bitcoin blockchain only contains timestamps for blocks, and no timestamps for individual transactions. This means we could not analyze transaction confirmation time in our unsupervised experiment, as this requires the timestamp of creating a transaction. However, prediction and analysis of confirmation times in Bitcoin have already been performed multiple times in recent literature~\citep{kawase2017transaction}~\citep{koops2018predicting}.

\section{Supervised experiments}
During several supervised experiments, we were in control of a network of 10 Android devices, of which 5 virtual emulators and 5 real world devices. By performing several experiments, throughput and latency of several actions in this network is analyzed. Performing measurements in different network sizes (2 up to 10 devices), enables making predictions of the scalability of MusicDAO.

\subsection{Downloading and streaming}
\ref{fig:download-times} shows the download time of each stage in the bittorrent downloading process. By running 10 runs per network configuration, we inspected the effects of a bittorrent tracker on throughput and handshake time. The 4 different download stages marked in this figure are as follows.

\begin{enumerate}
    \item Time to receive metadata (including establishing handshake)
    \item Time to fill stream buffer
    \item Time to download first track
    \item Time to download full album
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{evaluation/download-times.png}
    \caption{Average time spent per download stage. Measured by 20 runs in total, in two different network configurations.}
    \label{fig:download-times}
\end{figure}

The measurements show that a BitTorrent tracker significantly reduces transfer times, for a small BitTorrent swarm with 5 seeders. The largest difference is in the \textit{fetching metadata} stage, during which the device under test must find and connect with seeders. Discovering seeders over DHT requires asking multiple peers, and as such requires more time and messages before the download can start. Once the download starts, the runs using a tracker also reach significantly higher throughput, as the tracker assists the device in finding more seeders and healthier seeders. We found that the major factor slowing down download stages when using DHT only is the NAT puncturing stage, where devices try to connect to each other when there are one or more NAT devices in between. As expected, finding peers over DHT is also slower than via a tracker, however the time taken to create a handshake during NAT puncturing has a much larger effect on the peer-to-peer connecting time (the time taken to create a reliable connection for data transfer). 

\ref{fig:download-traces} shows 5 traces of downloading a 38 Megabyte album. The red line shows the moving average over these 5 runs. The slow-start nature of BitTorrent can be observed here. Roughly the first 5 seconds are used for fetching the BitTorrent metadata (see also \ref{fig:download-times}).

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{evaluation/download-traces.png}
    \caption{5 traces of download throughput, downloading an album of around 38 Mbs. Measured with Nokia 7.}
    \label{fig:download-traces}
\end{figure}

The datasets used to create the plots shown in figs. \ref{fig:artist-income} and \ref{fig:transactions} are received by scraping blockchain block data from our Bitcoin node. Fig. \ref{fig:artist-income} shows the relation between created blocks and money transacted per block (cumulative). We observe that, during the timeline of the release experiment, nearly 500 BTC has been received by artists.

Note that all devices evaluated in experiments \ref{fig:download-times} and \ref{fig:download-traces} use Bittorrent Local Peer Discovery. This means that some of the data transfers may be over local area network, which reaches considerably higher throughput than regular transfers over TCP across NATs.

\subsection{File headers and BitTorrent piece ordering}
The streaming algorithm implemented and evaluated uses the BitTorrent priorities system. The first $x=5$ pieces at the selected portion of the file (by default, the start of the file) have a higher priority than the other pieces. However, even though some pieces $A$ have higher priority than other pieces $B$, BitTorrent does not guarantee that all $a\in A$ are received earlier before any $b\in B$. Therefore, the actual ordering of the received pieces is non-deterministic. The simple heuristic used in the streaming algorithm is: start playing the file when 30\% has been downloaded; but this does not always work and this leads to inconsistent stream buffer times. Additionally, we use the assumption that the header of the audio file is at the first few bytes of the file, but this is not always true.

There is significant ongoing research related to peer-to-peer streaming in literature that can be used to improve our streaming algorithm~\citep{erman2008piece}~\citep{akkanen2017continuous}.

\subsection{Content discovery}
Fig. \ref{fig:content-discovery} shows measurements of an Android device discovering content, after running MusicDAO for the first time. More specifically, it is a measurement of music metadata, received as TrustChain blocks. All participating devices are configured as follows: Every device sends a random block to a random peer every 5 seconds. A Nokia 7 Android device ran the MusicDAO in an idle state for 5 minutes. The app measured the amount of content metadata discovered every 2 seconds. 

\subsubsection{\textbf{Mathematical model}}
For evaluating content discovery over time, we compare three different experiments with a mathematical model for expected discovered items over time.

\begin{itemize}
    \item Gossip interval $t=5$ seconds
    \item Total items to discover: $R=50$
\end{itemize}

Every time interval, all devices send one music block to a random neighbor. As such, the expected amount of blocks received in one interval is 1. When receiving a music block, the chance that it is a block that has not been received before is $$\frac{R-r}{R}$$ with $r\leq R$ the amount of items received so far. It follows that the expected value for the cumulative amount of unique items discovered after $x$ iterations is $$E[R]=R(1-(\frac{R-1}{R})^{x})$$ where $$x=\frac{1}{t}$$ This expected value $E[R]$ over time is plotted in \ref{fig:content-discovery} as Model.

As every device sends one item per time interval to a neighbor, the gossiped items per time interval is equal to network size $n$. This means message complexity $M$ is equal to network size: $$M=O(n)$$

Every device participating in gossiping sends 1 message and receives, on average, 1 message back. So the expected messages to process is $E[M]=2$ per iteration. Therefore the message complexity for a single device is $$M=O(1)$$ This means that the network size does not affect the message processing workload of each device, and makes the algorithm highly scalable.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{evaluation/expected-vs-simulated-releases.png}
    \caption{Measurements of content discovery: releases discovered after a fresh installation. $n$: network size (amount of Android devices)}
    \label{fig:content-discovery}
\end{figure}

In \ref{fig:content-discovery} we can see a correlation between model and experiment for network sizes $n=2$ and $n=4$. For $n=10$ the experiment and model correlate until 3 minutes into the experiment. The reasons for this are for now not clear. More investigation and more experiments on larger networks are necessary to make conclusions.

\subsection{Random access latency}
Random access latency of metadata is evaluated through measuring search latency. Search latency is the round-trip time between initiating keyword search and receiving metadata for the release. During this experiment, the content that was searched for was present in all devices except the one under test. The distributed search algorithm (alg. \ref{alg:algorithm-distributed-search}) is used with the following parameters.

\begin{itemize}
    \item $maxPeers=20$
    \item $ttl=1$ 
\end{itemize}

This means that a maximum of 20 neighbors are contacted when performing a search, and that search is not recursive; meaning only neighbors are contacted (not neighbors of neighbors).

For two different situations, 10 runs are done and the latency and average latency are plotted in \ref{fig:search-latency}. We observe that for these 20 runs, latency is $<1s$. Another observation is: increase in network size (10 versus 2) does not negatively affect latency. Current music streaming systems have a search latency of roughly $<2s$ in ideal situations.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{evaluation/search-latency.png}
    \caption{Search latency of performing keyword search}
    \label{fig:search-latency}
\end{figure}

It should be noted that message complexity of the search algorithm grows exponentially with the value of \textit{time-to-live} (ttl). For time-to-live $T$ and the maximum number of neighboring peers to ask $P$, the amount of messages for a single search is $p^T$ for $p\leq P$. This leaves a message complexity of $O(P^T)$. This could be improved by using a different distributed data structure that is optimized for search, such as a balance tree or a distributed hash table. 

\section{Devices behind NATs}
During experimentation, some of the Bittorrent traffic on Android devices were blocked by Network Address  Translators (NATs). MP3 transfers over Bittorrent were slowed down by this. The NAT Port Mapping Protocol (NAT-PMP) was used to be able to establish connections between different devices. NAT-PMP establishes connections using port scanning and port forwarding. However, this is a lengthy process: we observed that establishing such a connection usually takes more than 2 minutes. Analyzing and improving this process should be investigated in future distributed systems research.

\section{Transaction fees}
We use Bitcoin as peer-to-peer electronic cash system. Bitcoin uses transaction fees for every transaction. In our unsupervised experiments with MusicDAO, we observed an average transaction fee of 0.00003778 coins. As such we cannot say that artists receive 100\% of the donation money from users, but rather roughly 99.9996\%. This fee is calculated dynamically. It is based on the size of a transaction, and network conditions such as congestion. 

Our framework for the robot economy does not explicitly state the type of currency used. In MusicDAO, Bitcoin can be trivially swapped for any other currency as long as that currency uses a digital peer-to-peer public key infrastructure with public wallet addresses. As such, a different crypto-currency with no transaction fees (such as Nano~\citep{lemahieu2018nano}) can be used.

\section{Scalability}
We presented an infrastructureless network of phones that together form a fully operating application. During supervised experiments, a network size of up to 10 phones was used. Now we present our expectations of scalability beyond 10 active devices. 

As every device cooperates in the network by being both an uploader and downloader for content, the network size should not affect download speeds for users. The bandwidth, processing power and storage capacity of the application should naturally grow with the amount of users. An important note is that we do not take into account free-riders (peers that use the network but do not deliver resources) or adversaries (peers that perform attacks such as network flooding or sybil attack).

TrustChain DLT is highly scalable as it does not require global consensus. Instead, it uses a single blockchain per user instead of a single global blockchain. 

% \section{Content moderation and publishing protocol}
% We do not present a 

% Music publishing currently requires a block signing/agreement from one other peer, before it is added to the TrustChain and sent to other peers.  

\section{Bitcoin node}
We made use of a bitcoin node, running on a dedicated server continuously throughout the experimentation phase.

\section{P2P bootstrap problem}
Our goal, as described in the Design section, was to create a phone-only network. This is not fully accomplished as we use a bootstrap node to tackle the \textit{peer-to-peer bootstrap problem}. As recognized by \cite{wolinsky2010addressing}, the peer-to-peer bootstrap problem is the problem of finding peers in a P2P overlay network, when there are no connected peers to begin with. This is a widely known, yet unsolved problem for any peer-to-peer network, and it is also relevant in MusicDAO. 

It must be noted that a bootstrap node is not necessary when you can connect to a peer that is already on the MusicDAO network, for example via a local area network or Bluetooth. Moreover, a bootstrap node can be discarded once the bootstrapping procedure is successful.

\section{Battery usage}
The challenge of any peer-to-peer mobile app is battery usage, as it should be connected and contribute to the network as much as possible to optimally support other peers. To do this, TrustChain Superapp sends regular keep-alive messages in order to track the status of peers. To do this, the Superapp runs in the background as an Android service. Therefore it can still be used when the app is closed. The downside is that this appears to have a major effect on battery usage, as found in previous experimentation by \cite{mattskala2020}. He found that, during a 10 hour experiment, when a Google Pixel phone runs the app in the background and is connected to 20 peers, its battery consumption is roughly 10 times higher than normally. 

Battery usage could be improved by adjusting the peer-to-peer connectivity protocol of IPv8, such as by reducing the interval of keepalive messages. This requires further investigation and more research.

% Mention philisophical problem: The problem of shared responsibility (+citations)
% The problem of "Who is responsible when shit hits the fan"